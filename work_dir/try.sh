DMLC_NUM_WORKER=1 DMLC_ROLE=scheduler DMLC_NUM_SERVER=1 DMLC_PS_ROOT_URI=127.0.0.1 DMLC_PS_ROOT_PORT=1234 BYTEPS_FORCE_DISTRIBUTED=1 bpslaunch &
DMLC_NUM_WORKER=1 DMLC_ROLE=server DMLC_NUM_SERVER=1 DMLC_PS_ROOT_URI=127.0.0.1 DMLC_PS_ROOT_PORT=1234 BYTEPS_FORCE_DISTRIBUTED=1 bpslaunch &
CUDA_VISIBLE_DEVICES=0,1 NVIDIA_VISIBLE_DEVICES=0,1 DMLC_WORKER_ID=0 \
DMLC_NUM_WORKER=1 DMLC_ROLE=worker DMLC_NUM_SERVER=1 DMLC_PS_ROOT_URI=127.0.0.1 DMLC_PS_ROOT_PORT=1234 BYTEPS_FORCE_DISTRIBUTED=1 \
bpslaunch python3 /root/github/gradient-compression/byteps/example/pytorch/train_mnist_byteps.py --fp16-pushpull &


